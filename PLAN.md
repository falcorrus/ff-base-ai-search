# Техническое задание (ТЗ): Веб-приложение интеллектуального поиска по заметкам с использованием FastAPI (8 сентября 2025)

---

## 1. Общее описание и цели проекта

**Продукт:** Веб-приложение для поиска и получения комплексных ответов на основе личной базы знаний, состоящей из Markdown заметок, хранящихся в репозитории GitHub `falcorrus/ff-base`.

**Цель:** Обеспечить пользователю быстрый и точный поиск по заметкам с помощью векторного поиска и генерации единого ответа с использованием LLM (Google Gemini).

---

## 2. Область применения и ограничения

- Исходные данные: Markdown (.md) заметки в публичном репозитории GitHub `falcorrus/ff-base` (доступ только для чтения).
- Доступ к заметкам через GitHub API.
- Работа с данными осуществляется только в режиме чтения.
- Приложение ориентировано на одного пользователя (открытый доступ по ссылке).
- Объем базы — до 1000 заметок.
- Поддержка десктопных и мобильных браузеров.

---

## 3. Функциональные требования

### 3.1 Архитектура и обработка данных

- Ежедневная или триггерная синхронизация с GitHub репозиторием `falcorrus/ff-base` (через Webhooks или Cron job).
- Генерация и хранение векторов embeddings для каждой заметки в локальном JSON-файле.
- Поисковый API:
  - Получение поискового запроса от пользователя.
  - Преобразование запроса в embedding через LLM API (Google Gemini).
  - Поиск релевантных embeddings в локальном JSON.
  - Загрузка соответствующих Markdown файлов с GitHub по API.
  - Формирование контекста из загруженных заметок.
  - Отправка контекста в LLM API для получения комплексного ответа.
  - Возврат единого сгенерированного ответа пользователю через API.

### 3.2 Пользовательский интерфейс (Frontend)

- Главная страница с простой строкой поиска типа google.com.
- Отображение единого ответа под строкой поиска.
- Поиск запускается по кнопке «Искать» или нажатию Enter.
- Кнопка «назад» для возврата к пустой строке поиска.
- Опционально: ссылки на исходные заметки в ответе для просмотра.

### 3.3 Логирование и безопасность

- Логирование всех запросов (в JSON-файле) с указанием времени и текста запроса.
- Авторизация не предусмотрена на данном этапе.
- Защищенный доступ к GitHub API с использованием токенов.

---

## 4. Технические требования

### Backend

- Язык: Python 3.9+
- Фреймворк: FastAPI
- Асинхронная обработка запросов
- Интеграция с GitHub API для получения Markdown заметок из репозитория `falcorrus/ff-base`
- Хранение embeddings (до 1000 заметок) в локальном JSON-файле или переход на специализированное векторное хранилище при росте базы
- Интеграция с LLM API Google Gemini (используется модель `gemini-1.5-flash` для генерации ответов)
- Логирование всех запросов в JSON-файле с таймстампами
- Backend разворачивается на **Google Cloud Run**, что обеспечивает автоматическое масштабирование, простоту интеграции с Google API и достаточно бесплатной квоты для низкой нагрузки

### Фронтенд

- Размещение на **Firebase Hosting** (или другой статической платформе Google Cloud)
- Минималистичный интерфейс с быстрой загрузкой и поисковой строкой
- Реализация UI на **Vanilla JS**
- Асинхронный вызов backend API для поиска и получения ответов
- Полная интеграция с экосистемой Google Cloud для удобства деплоя, безопасности и масштабируемости

---

## 5. Рабочий процесс

1. Пользователь вводит запрос и запускает поиск.
2. Backend преобразует запрос в вектор, ищет релевантные заметки.
3. Загружает Markdown файлы с найденными заметками с GitHub.
4. Передаёт тексты заметок в LLM для генерации единого ответа.
5. Отправляет сгенерированный ответ и ссылки на заметки в frontend.
6. Пользователь читает ответ, при необходимости возвращается к поиску или переключается на просмотр заметок.

---

## 6. Перспективы развития

- Добавление авторизации и разграничения доступа.
- Миграция на специализированное векторное хранилище при росте базы. Скорее всего Chromadb.
- Оптимизация загрузки заметок с Github
- Оптимизация работы с длинным контекстом LLM.

---

## 7. Особенности реализации

- Главная страница загружается максимально быстро с отображением строки поиска.
- Embeddings загружаются асинхронно в фоне на сервере.
- Поисковый запрос обрабатывается, найденные заметки подгружаются с GitHub параллельно.
- Объединённый контекст передаётся в LLM для формирования комплексного ответа.
- Ограничение по токенам при работе с LLM реализуется через сегментацию или сокращение контекста.

## 8. Текущий статус реализации

### Завершено:
1. Настроен бэкенд на FastAPI
2. Реализована интеграция с GitHub API для получения файлов из репозитория `falcorrus/ff-base`
3. Добавлена поддержка Google Gemini API для генерации embeddings и ответов
4. Реализованы эндпоинты:
   - `/` - главная страница
   - `/update-knowledge-base` - обновление базы знаний из GitHub
   - `/search` - поиск по заметкам с генерацией ответа

### В процессе:
1. Разработка фронтенда с полем поиска и отображением результатов
2. Настройка логирования запросов
3. Оптимизация поиска и генерации ответов

### Предстоит:
1. Деплой бэкенда на Google Cloud Run
2. Деплой фронтенда на Firebase Hosting
3. Тестирование и отладка