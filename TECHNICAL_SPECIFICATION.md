### **Техническое Задание: "Intelligent Search" (ff-base-ai-search)**

**Версия:** 1.0
**Дата:** 4 сентября 2025 г.

#### 1. Введение

Настоящее техническое задание описывает требования к разработке веб-приложения "Intelligent Search". Приложение предназначено для осуществления семантического поиска по базе знаний пользователя, хранящейся в виде Markdown-файлов в репозитории GitHub. Основная цель системы — не просто находить релевантные документы, но и синтезировать ответы на естественном языке на основе извлеченной информации, используя подход Retrieval-Augmented Generation (RAG).

#### 2. Цели и Задачи Проекта

*   **Цель:** Создать интуитивно понятный и мощный инструмент для поиска информации в личных или корпоративных базах знаний, превосходящий традиционный поиск по ключевым словам.
*   **Задачи:**
    *   Разработать удобный веб-интерфейс для взаимодействия с системой.
    *   Реализовать механизм синхронизации с репозиторием GitHub пользователя.
    *   Создать сервис для векторизации текстового содержимого заметок.
    *   Реализовать API для выполнения семантического поиска.
    *   Интегрировать генеративную языковую модель (LLM) для формирования кратких, обобщенных ответов.

#### 3. Целевая Аудитория

*   Пользователи приложений для ведения заметок, таких как Obsidian и Notion, которые хранят свои данные в Git-репозиториях.
*   Технические специалисты, исследователи и все, кто работает с большими объемами текстовой информации и нуждается в эффективных возможностях поиска.

#### 4. Технологический Стек

*   **Фронтенд:**
    *   Язык: TypeScript
    *   Фреймворк: Vanilla JS/TS + HTMX
    *   Стилизация: Tailwind CSS
*   **Бэкенд:**
    *   Платформа: Node.js
    *   Язык: TypeScript
    *   Фреймворк API: Express.js
*   **Векторная База Данных:**
    *   Продакшн: ChromaDB / Pinecone / FAISS (планируется)
    *   Прототип: Локальный JSON-файл
*   **Внешние API:**
    *   GitHub API (для доступа к файлам и синхронизации)
    *   Google Gemini API (для генерации векторных эмбеддингов и ответов LLM)

#### 5. Архитектура Системы

Система будет состоять из трех основных компонентов:

1.  **Клиент (Frontend):** Одностраничное приложение (SPA), отвечающее за рендеринг пользовательского интерфейса, управление состоянием приложения и взаимодействие с бэкенд API.
2.  **Сервер (Backend):** Приложение Node.js, предоставляющее REST API для клиента. Оно обрабатывает поисковые запросы, взаимодействует с векторной базой данных и обменивается данными с LLM.
3.  **Воркер/Индексатор:** Фоновый процесс (потенциально интегрированный в бэкенд), который периодически сканирует указанный репозиторий GitHub, обнаруживает изменения и обновляет векторную базу данных новыми или измененными эмбеддингами документов.

#### 6. Функциональные Требования

**6.1. Аутентификация и Подключение Репозитория**
*   Пользователи должны иметь возможность подключить свою учетную запись GitHub через OAuth.
*   После успешной аутентификации пользователи должны выбрать публичный или приватный репозиторий GitHub, который будет служить источником их знаний.

**6.2. Синхронизация и Индексация**
*   Система должна автоматически сканировать указанный репозиторий при первом подключении.
*   Все файлы с расширением `.md` должны быть обработаны.
*   Текстовое содержимое каждого файла должно быть отправлено в AI-сервис (Google Gemini API) для получения его векторного представления (эмбеддинга).
*   Сгенерированный вектор, наряду с соответствующими метаданными (путь к файлу, заголовок), должен быть сохранен в векторной базе данных.
*   Должен быть реализован механизм периодической или webhook-основанной синхронизации для обновления индекса при изменениях в репозитории.

**6.3. Поисковый Интерфейс**
*   Главный экран приложения должен содержать заметную строку поиска.
*   Пользователи будут вводить запросы на естественном языке в строку поиска.
*   Запросы будут отправляться на бэкенд для обработки по мере их ввода.

**6.4. Логика Поиска (Backend)**
*   Бэкенд будет получать поисковый запрос от клиента.
*   Запрос будет векторизован с использованием той же модели эмбеддингов, что и для документов.
*   Будет выполнен поиск по векторной базе данных для нахождения `N` наиболее семантически похожих документов (на основе косинусного сходства).
*   Содержимое извлеченных документов и исходный поисковый запрос будут переданы генеративной языковой модели (LLM).

**6.5. Генерация Ответа и Отображение Результатов**
*   LLM получит контекст из найденных документов и сформирует краткий, связный ответ на исходный вопрос пользователя.
*   Клиент будет отображать:
    1.  Сгенерированный AI-ответ в верхней части экрана.
    2.  Список найденных исходных документов, представленных в виде карточек. Каждая карточка будет включать заголовок, фрагмент текста и ссылку на исходный файл в GitHub.
*   Нажатие на карточку результата должно позволять пользователю просмотреть полное содержимое заметки, либо во всплывающем окне, либо на отдельной странице.

#### 7. Нефункциональные Требования

*   **Производительность:** Время ответа на поисковый запрос не должно превышать 3-5 секунд.
*   **Масштабируемость:** Архитектура должна быть способна обрабатывать более 10 000 заметок без значительного снижения производительности.
*   **Безопасность:** Все ключи API и токены доступа пользователей должны храниться в зашифрованном виде и не должны быть доступны на стороне клиента.
*   **UI/UX:** Пользовательский интерфейс должен быть минималистичным, адаптивным и интуитивно понятным.

#### 8. План Развертывания

*   **Фронтенд:** Развертывание на платформе Vercel.
*   **Бэкенд:** Развертывание в виде бессерверных функций (Vercel Functions) или на отдельном хостинге (например, Render, Railway).
*   **CI/CD:** Настройка GitHub Actions для автоматической сборки и развертывания при изменениях в ветке `main`.